# Requirements for FP8 training (requires NVIDIA H100/H200 GPU)
-r requirements.txt

# Transformer Engine - Provides FP8 support
# Utiliser la dernière version stable de transformer-engine (>= 1.3.0)
transformer-engine>=1.3.0

# PyTorch avec support CUDA 12.x (nécessaire pour transformer-engine)
--extra-index-url https://download.pytorch.org/whl/cu121
torch>=2.1.0

# Additional dependencies for FP8 support
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cudnn-cu12==8.9.2.26
nvidia-cublas-cu12==12.1.3.1
nvidia-cufft-cu12==11.0.2.54
nvidia-nccl-cu12==2.19.3

# NVTX for profiling FP8 operations
torch-tensorrt>=1.4.0

# For optimized attention operations with FP8
flash-attn>=2.3.4 